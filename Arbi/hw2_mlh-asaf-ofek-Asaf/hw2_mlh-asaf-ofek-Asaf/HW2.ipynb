{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretical questions\n",
    "Q1: To evaluate how well our model performs at T1D classification, we need to have evaluation metrics that measures of its performances/accuracy. Which evaluation metric is more important to us: model accuracy or model performance? Give a simple example that illustrates your claim.\n",
    "\n",
    "A1: Performance means how good our model is doing its job. Accuracy is the number of correct predictions made by the model by the total number of records. For us, performance is more important beacuse accuracy can be deceiving if the data is not representive enough.\n",
    "For instance, if we use a binary naive classifier to determine whether a person has cancer, However the data only includes 5 positive cases out of 100 patients, we get 95% accuracy.\n",
    "\n",
    "Q2: T1D is often associated with other comorbidities such as a heart attack. You are asked to design a ML algorithm to predict which patients are going to suffer a heart attack. Relevant patient features for the algorithm may include blood pressure (BP), body-mass index (BMI), age (A), level of physical activity (P), and income (I). You should choose between two classifiers: the first uses only BP and BMI features and the other one uses all of the features available to you. Explain the pros and cons of each choice.\n",
    "\n",
    "A2: \n",
    "\n",
    "Using BMI and BP:\n",
    "    \n",
    "    pros\n",
    "      - Weights will be easier to find.\n",
    "      - The calculations will be simpler.\n",
    "      - Data cleanning will only include two coloumns.\n",
    "    cons\n",
    "      - We can't be sure that these are the most important features. This can lead to diminished performance and crucial mistakes. \n",
    "        For example, a false negative case; One may not be treated well which can lead to devastating consequences.\n",
    "    \n",
    "Using all features:\n",
    "\n",
    "    pros\n",
    "      - The model will most likely perform better and will have better accuracy (under the assumption that our data is reliable enough)\n",
    "    cons\n",
    "      - Data exploration and cleanning will be difficult.\n",
    "      - We'll have a lot of data meanning extended computation time.\n",
    "    \n",
    "        \n",
    "\n",
    "Q3: A histologist wants to use machine learning to tell the difference between pancreas biopsies that show signs of T1D and those that do not. She has already come up with dozens of measurements to take, such as color, size, uniformity and cell-count, but she isnâ€™t sure which model to use. The biopsies are really similar, and it is difficult to distinguish them from the human eye, or by just looking at the features. Which of the following is better: logistic regression, linear SVM or nonlinear SVM? Explain your answer.\n",
    "\n",
    "A3:\n",
    "\n",
    "We can assume that the data won't be linearly seperable since the samples look alike and have similar properties.\n",
    "Thus, we will use nonlinear SVM to find the correct boundary line.\n",
    "\n",
    "Q4: What are the differences between LR and linear SVM and what is the difference in the effect/concept of their hyper-parameters tuning?\n",
    "\n",
    "A4: LR - returns the probabilities to be a part of a certain class. \n",
    "\n",
    "Linear SVM - returns where each patient will be labeled.\n",
    "\n",
    "There is one hyperparameter to tune - lambda (or C in python which is 1/lambda). \n",
    "This hyperparameter determines the bias - variance tradeoff, meaning that for low values of lambda (or high values of C), our model can be complex and we risk overfitting our training examples(high variance). in this case the model will memorise, not learn.\n",
    "\n",
    "For high values of lambda (or low values of C) we \"punish\" harder our model for each misclassification and risk having an underfit condition, meaning that our model will be too simple (high bias).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the relevant packages and write two functions.\n",
    "The first is nan2num, which replaces all nan values with random numbers from the same coloumn.\n",
    "\n",
    "The second is str_to_bool_series which will help us classify later.\n",
    "Except age, all categories can be binarized as follows:\n",
    "\n",
    "Yes = true ; No = false\n",
    "\n",
    "Male = true ; Female = false\n",
    "\n",
    "Positive = True ; Negative = false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import distutils\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('HW2_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan2num(dataframe):\n",
    "    \n",
    "    #:param dataframe: Pandas series of features\n",
    "    #:return: A pandas dataframe of the dictionary c_cdf containing the \"clean\" features\n",
    "    \n",
    "    # dataframe = pd.DataFrame(dataframe).drop(extra_feature, 1)\n",
    "    c_cdf = {}\n",
    "    c_cdf = dataframe\n",
    "    for column in dataframe.columns:\n",
    "        if column == 'Age':\n",
    "            i=0\n",
    "        else:\n",
    "            replacing_value = np.random.choice(dataframe[column])\n",
    "            c_cdf[column].replace(to_replace=np.nan, value=replacing_value, inplace=True)\n",
    "    return pd.DataFrame(c_cdf)\n",
    "\n",
    "def str_to_bool_series(s):\n",
    "    for index, value in s.items():\n",
    "        if(value=='Yes'):\n",
    "            s[index] = True\n",
    "        elif(value=='No'):\n",
    "            s[index] = False\n",
    "        elif(value=='Male'):\n",
    "            s[index] = True\n",
    "        elif(value == 'Female'):\n",
    "            s[index] = False\n",
    "        elif(value=='Positive'):\n",
    "            s[index] = True\n",
    "        elif (value == 'Negative'):\n",
    "            s[index] = False\n",
    "#         elif(value==1):\n",
    "#             s[index] = True\n",
    "#         elif(value==0):\n",
    "#             s[index] = False\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get the clean data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Gender  Increased Urination  Increased Thirst  Sudden Weight Loss  \\\n",
      "0     45    True                False             False               False   \n",
      "1     42    True                False             False               False   \n",
      "2     45    True                 True              True               False   \n",
      "3     59   False                False             False               False   \n",
      "4     40   False                 True              True                True   \n",
      "..   ...     ...                  ...               ...                 ...   \n",
      "560   54    True                 True              True                True   \n",
      "561   32    True                False             False               False   \n",
      "562   61   False                 True             False               False   \n",
      "563   46    True                False             False               False   \n",
      "564   37    True                False             False               False   \n",
      "\n",
      "     Weakness  Increased Hunger  Genital Thrush  Visual Blurring  Itching  \\\n",
      "0        True             False           False            False     True   \n",
      "1       False             False           False            False    False   \n",
      "2        True             False            True            False    False   \n",
      "3       False             False           False            False    False   \n",
      "4        True             False           False             True     True   \n",
      "..        ...               ...             ...              ...      ...   \n",
      "560      True             False           False             True     True   \n",
      "561     False             False           False            False    False   \n",
      "562     False              True           False            False    False   \n",
      "563      True             False           False            False     True   \n",
      "564     False             False           False            False    False   \n",
      "\n",
      "     Irritability  Delayed Healing  Partial Paresis  Muscle Stiffness  \\\n",
      "0           False            False             True             False   \n",
      "1           False            False            False             False   \n",
      "2           False             True            False             False   \n",
      "3           False            False            False             False   \n",
      "4           False            False             True              True   \n",
      "..            ...              ...              ...               ...   \n",
      "560          True             True             True              True   \n",
      "561          True             True            False             False   \n",
      "562          True            False            False             False   \n",
      "563         False             True            False             False   \n",
      "564         False            False            False             False   \n",
      "\n",
      "     Hair Loss  Obesity  Diagnosis  Family History  \n",
      "0         True    False      False               0  \n",
      "1         True    False      False               0  \n",
      "2         True    False       True               0  \n",
      "3        False    False       True               1  \n",
      "4        False    False       True               0  \n",
      "..         ...      ...        ...             ...  \n",
      "560      False    False       True               0  \n",
      "561      False     True       True               0  \n",
      "562       True    False       True               1  \n",
      "563       True    False      False               0  \n",
      "564      False    False      False               0  \n",
      "\n",
      "[565 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "df=nan2num(df)\n",
    "for coloumn in df.columns:\n",
    "    df[coloumn]=str_to_bool_series(df[coloumn])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - Test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
